
from fastapi import FastAPI, Request
import os
import requests
from telegram import Bot
from telegram.constants import ParseMode
from bs4 import BeautifulSoup
import re
from datetime import datetime, date, timedelta
import json

app = FastAPI()

TOKEN = os.getenv("TOKEN")
if not TOKEN:
    raise ValueError("TOKEN is not set!")

ADMINS = os.getenv("ADMINS", "")
print("initial ADMINS is:", ADMINS)
ADMINS = [int(x.strip()) for x in ADMINS.split(",") if x.strip().isdigit()]

user_preferences = {}  # Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ØªÙ„ÙØ¸ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
user_pos = {}  # Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Ø¹ÛŒØª ØªÙ„ÙØ¸ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† (br/us)
USER_FILE = "users.json"

API_URL = f"https://api.telegram.org/bot{TOKEN}/sendMessage"

# ----------------- UTILITIES -----------------
def save_user(user_id):
    try:
        users = {}
        if os.path.exists(USER_FILE):
            with open(USER_FILE, "r") as f:
                users = json.load(f)
        if user_id not in ADMINS and str(user_id) not in users:
            users[str(user_id)] = datetime.now().strftime("%Y-%m-%d")
            with open(USER_FILE, "w") as f:
                json.dump(users, f)
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ø±Ø¨Ø±:", e)

def get_user_stats():
    try:
        if not os.path.exists(USER_FILE):
            return {"total": 0, "today": 0, "yesterday": 0}

        with open(USER_FILE, "r") as f:
            users = json.load(f)
        total = len(users)
        today = date.today().isoformat()
        yesterday = (date.today() - timedelta(days=1)).isoformat()

        today_count = sum(1 for d in users.values() if d == today)
        yesterday_count = sum(1 for d in users.values() if d == yesterday) + 1

        return {
            "total": total if total > 1 else 1,
            "today": today_count if today_count > 1 else 1,
            "yesterday": yesterday_count if yesterday_count > 1 else 1
        }
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ù…Ø§Ø±:", e)
        return {"total": 1, "today": 1, "yesterday": 1}
# ----------------- LONGMAN PARSER -----------------
# Ù„ÛŒØ³Øª ØªØ¨Ø¯ÛŒÙ„ Ø§Ù…Ù„Ø§ÛŒ Ø¢Ù…Ø±ÛŒÚ©Ø§ÛŒÛŒ Ø¨Ù‡ Ø¨Ø±ÛŒØªÛŒØ´
american_to_british = {
 'acknowledgement': 'acknowledgment',
 'aluminium': 'aluminum',
 'anaemia': 'anemia',
 'analog': 'analog',
 'analyse': 'analyze',
 'analyze': 'analyse',
 'anemia': 'anaemia',
 'apologise': 'apologize',
 'apologize': 'apologise',
 'appal': 'appall',
 'appals': 'appalls',
 'appetiser': 'appetizer',
 'appetizer': 'appetiser',
 'arbour': 'arbor',
 'ardour': 'ardor',
 'armour': 'armor',
 'behavior': 'behaviour',
 'behaviour': 'behavior',
 'caecum': 'cecum',
 'caesium': 'cesium',
 'caliber': 'calibre',
 'calibre': 'caliber',
 'candour': 'candor',
 'catalogue': 'catalog',
 'catalyse': 'catalyze',
 'catalyze': 'catalyse',
 'cecum': 'caecum',
 'celiac': 'coeliac',
 'center': 'centre',
 'centre': 'center',
 'cesium': 'caesium',
 'civilise': 'civilize',
 'civilize': 'civilise',
 'clamour': 'clamor',
 'coeliac': 'celiac',
 'colonise': 'colonize',
 'colonize': 'colonise',
 'color': 'colour',
 'colour': 'color',
 'counseling': 'counselling',
 'counselling': 'counseling',
 'counsellor': 'counselor',
 'counselor': 'counsellor',
 'criticise': 'criticize',
 'criticize': 'criticise',
 'defence': 'defense',
 'defense': 'defence',
 'demeanour': 'demeanor',
 'emphasise': 'emphasize',
 'emphasize': 'emphasise',
 'encyclopaedia': 'encyclopedia',
 'encyclopedia': 'encyclopaedia',
 'endeavor': 'endeavour',
 'endeavour': 'endeavor',
 'enrollment': 'enrolment',
 'enrolment': 'enrollment',
 'equaling': 'equalling',
 'equalling': 'equaling',
 'estrogen': 'oestrogen',
 'favorite': 'favourite',
 'favour': 'favor',
 'favourite': 'favorite',
 'fervour': 'fervor',
 'fiber': 'fibre',
 'fibre': 'fiber',
 'flavor': 'flavour',
 'flavour': 'flavor',
 'foetus': 'fetus',
 'fueled': 'fuelled',
 'fueling': 'fuelling',
 'fuelled': 'fueled',
 'fuelling': 'fueling',
 'fulfil': 'fulfill',
 'fulfill': 'fulfil',
 'fulfils': 'fulfills',
 'glamor': 'glamour',
 'glamour': 'glamor',
 'goitre': 'goiter',
 'harbour': 'harbor',
 'honor': 'honour',
 'honour': 'honor',
 'humor': 'humour',
 'humour': 'humor',
 'installment': 'instalment',
 'instalment': 'installment',
 'instil': 'instill',
 'instils': 'instills',
 'jewellery': 'jewelry',
 'jewelry': 'jewellery',
 'kilometer': 'kilometre',
 'kilometre': 'kilometer',
 'labor': 'labour',
 'labour': 'labor',
 'leukaemia': 'leukemia',
 'leukemia': 'leukaemia',
 'licence': 'license', # noun in UK is 'licence', verb is 'license'
 'license': 'licence',
 'liter': 'litre',
 'litre': 'liter',
 'louver': 'louvre',
 'louvre': 'louver',
 'luster': 'lustre',
 'lustre': 'luster',
 'maneuver': 'manoeuvre',
 'manoeuvre': 'maneuver',
 'marvellous': 'marvelous',
 'meager': 'meagre',
 'meagre': 'meager',
 'mediaeval': 'medieval',
 'medieval': 'mediaeval',
 'memorise': 'memorize',
 'memorize': 'memorise',
 'meter': 'metre',
 'metre': 'meter',
 'minimise': 'minimize',
 'minimize': 'minimise',
 'modeling': 'modelling',
 'modelling': 'modeling',
 'mould': 'mold',
 'moult': 'molt',
 'moustache': 'mustache',
 'neighbor': 'neighbour',
 'neighbour': 'neighbor',
 'odor': 'odour',
 'odour': 'odor',
 'oesophagus': 'esophagus',
 'oestrogen': 'estrogen',
 'offence': 'offense',
 'offense': 'offence',
 'organise': 'organize',
 'organize': 'organise',
 'paediatric': 'pediatric',
 'paediatrician': 'pediatrician',
 'paedophile': 'pedophile',
 'paralyse': 'paralyze',
 'paralyze': 'paralyse',
 'parlour': 'parlor',
 'patronise': 'patronize',
 'patronize': 'patronise',
 'pediatric': 'paediatric',
 'pedophile': 'paedophile',
 'plough': 'plow',
 'practice': 'practise',   # noun in US/UK: practice; verb in UK: practise
 'practise': 'practice',
 'pretence': 'pretense',
 'pretense': 'pretence',
 'prise': 'prize',
 'prize': 'prise',
 'pyjamas': 'pajamas',
 'quarreling': 'quarrelling',
 'quarrelling': 'quarreling',
 'rancour': 'rancor',
 'realise': 'realize',
 'realize': 'realise',
 'recognise': 'recognize',
 'recognize': 'recognise',
 'revelled': 'reveled',
 'revelling': 'reveling',
 'rigour': 'rigor',
 'rumor': 'rumour',
 'rumour': 'rumor',
 'saber': 'sabre',
 'sabre': 'saber',
 'saviour': 'savior',
 'savor': 'savour',
 'savour': 'savor',
 'scepter': 'sceptre',
 'sceptre': 'scepter',
 'signaling': 'signalling',
 'signalling': 'signaling',
 'skilful': 'skillful',
 'skillful': 'skilful',
 'smoulder': 'smolder',
 'socialise': 'socialize',
 'socialize': 'socialise',
 'somber': 'sombre',
 'sombre': 'somber',
 'specialise': 'specialize',
 'specialize': 'specialise',
 'specter': 'spectre',
 'spectre': 'specter',
 'splendor': 'splendour',
 'splendour': 'splendor',
 'succour': 'succor',
 'theater': 'theatre',
 'theatre': 'theater',
 'traveled': 'travelled',
 'traveler': 'traveller',
 'traveling': 'travelling',
 'travelle': 'traveler',
 'travelled': 'traveled',
 'traveller': 'traveler',
 'travelling': 'traveling',
 'tumour': 'tumor',
 'valour': 'valor',
 'vapour': 'vapor',
 'vigor': 'vigour',
 'vigour': 'vigor',
 'whisky': 'whiskey',
 'wilful': 'willful'}
        
def build_longman_link(word):
    return f"https://www.ldoceonline.com/dictionary/{word.lower().replace(' ', '-')}"

# ----------------- OXFORD PARSER -----------------
def build_oxford_link(word):
    return f"https://www.oxfordlearnersdictionaries.com/definition/english/{word.lower().replace(' ', '-')}"

# ----------------- Process Word and Fetch dictionaries info -----------------
def has_invalid_parent_class(element):
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ù„Ø¯â€ŒÙ‡Ø§ÛŒ Ø¹Ù†ØµØ± ØªØ§ Ø±Ø³ÛŒØ¯Ù† Ø¨Ù‡ Ø±ÛŒØ´Ù‡
    parents = element.find_parents()
    for parent in parents:
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø´Ø§Ù…Ù„ Tail ÛŒØ§ DERIV Ù‡Ø³ØªÙ†Ø¯
        classes = parent.get('class', [])
        if isinstance(classes, list) and any(cls in classes for cls in ['Tail', 'DERIV']):
            return True
    return False

def getAudioUrl(audio_url, preferred, pos, word, chat_id, caption):
    if audio_url:
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            response = requests.get(audio_url, headers=headers)
            if response.status_code == 200 and response.headers["Content-Type"].startswith("audio"):
                safe_word = re.sub(r'[^\w\-]+', '_', word)
                file_name = f"{safe_word}_{preferred}_{pos}.mp3"

                with open(file_name, "wb") as f:
                    f.write(response.content)

                with open(file_name, "rb") as audio_file:
                    files = {'audio': audio_file}
                    data = {'chat_id': chat_id, 'caption': caption}
                    send_audio_url = f"https://api.telegram.org/bot{TOKEN}/sendAudio"
                    res = requests.post(send_audio_url, data=data, files=files)
                    print("ğŸ“¤ Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ:", res.json())

                os.remove(file_name)

        except Exception as e:
            error_reply = {
                "chat_id": chat_id,
                "text": f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ: {e}"
            } 
            res = requests.post(API_URL, json=error_reply)
            print("ğŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§:", res.json())
    else:
        fetch_oxford_audio_enabled = True
        reply = {
            "chat_id": chat_id,
            "text": f"âŒØªÙ„ÙØ· ØµÙˆØªÛŒ Ú©Ù„Ù…Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯"
        }
        res = requests.post(API_URL, json=reply)
        print("ğŸ“¤ØªÙ„ÙØ· ØµÙˆØªÛŒ Ú©Ù„Ù…Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯", res.json())
  
  
def fetch_longman_data(word):
    url = build_longman_link(word)
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            return []

        soup = BeautifulSoup(response.text, "html.parser")
        data = []

        entries = soup.find_all("span", class_="ldoceEntry Entry")
        
        for entry in entries:
            headword_tag = entry.find("span", class_="HWD")
            if not headword_tag:
                continue

            headword = headword_tag.get_text(strip=True).lower()
            if headword != word.lower() and headword != american_to_british[word]:
                continue  # ÙÙ‚Ø· Ù…Ø¯Ø®Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ù‚ÛŒÙ‚Ø§ Ø®ÙˆØ¯ Ú©Ù„Ù…Ù‡ Ù‡Ø³ØªÙ†Ø¯
            
            pos_tag = entry.find("span", class_="POS")
            phonetic_tag = entry.find("span", class_="PRON")
            speakers = entry.find_all("span", class_="speaker")

            if not pos_tag or not speakers:
                continue
            
            isPhoneticValid = True
            if phonetic_tag is not None:
                isPhoneticValid = has_invalid_parent_class(phonetic_tag)
                if(isPhoneticValid):
                    phonetic_tag = None 

            pos = pos_tag.get_text(strip=True)
            phonetic = phonetic_tag.get_text(strip=True) if phonetic_tag else None
            
            british_audio = None
            american_audio = None

            for spk in speakers:
                mp3_url = spk.get("data-src-mp3", "")
                if "breProns" in mp3_url and not british_audio:
                    british_audio = mp3_url
                elif "ameProns" in mp3_url and not american_audio:
                    american_audio = mp3_url

            if british_audio or american_audio:
                data.append({
                    "pos": pos,
                    "phonetic": phonetic,
                    "british": british_audio,
                    "american": american_audio
                })

        return data

    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ÙˆØ§Ú©Ø´ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù„Ø§Ù†Ú¯Ù…Ù†: {e}")
        return []

def fetch_oxford_audio(word, preferred_accent):
    url = build_oxford_link(word)
    headers = {"User-Agent": "Mozilla/5.0"}
    data = {
            "audio_url": None,
            "phonetic": None,
            "pos": None
        }  
    
    try:
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            print(f"âŒ Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ Ø¢Ú©Ø³ÙÙˆØ±Ø¯ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Status: {response.status_code}")
            return data

        soup = BeautifulSoup(response.text, "html.parser")
        
           # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú© mp3
        accent_class = 'pron-us' if preferred_accent == 'american' else 'pron-uk'

        audio_div = soup.find('div', class_=lambda c: c and
                         'sound' in c.split() and
                         'audio_play_button' in c.split() and
                         accent_class in c.split())
        accent_class_name = 'phons_n_am' if preferred_accent == 'american' else 'prons_br'     

        accent_div = soup.find("div", class_=accent_class_name)

        # Ø§Ú¯Ø± div Ù¾ÛŒØ¯Ø§ Ø¨Ø´Ù‡ØŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ data-src-mp3
        if audio_div and audio_div.has_attr('data-src-mp3'):
            audio_url = audio_div['data-src-mp3']
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ ÙÙˆÙ†ØªÛŒÚ© Ù‡Ù… Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ù‡
            phonetic_tag = accent_div.find("span", class_="phon")
            phonetic = phonetic_tag.get_text(strip=True) if phonetic_tag else None
            pos_tag = soup.find("span", class_="pos")
            pos = pos_tag.get_text(strip=True) if pos_tag else None
        else:
            print("âŒ ØµØ¯Ø§ Ø¨Ø±Ø§ÛŒ Ù„Ù‡Ø¬Ù‡ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ Ø¯Ø± Ø¢Ú©Ø³ÙÙˆØ±Ø¯ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
            return data   

        # Ø¨Ø§Ø²Ú¯Ø´Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ POS Ùˆ ØªÙ„ÙØ¸ ØµÙˆØªÛŒ
        data = {
            "audio_url": audio_url,
            "phonetic": phonetic,
            "pos": pos
        }
        return data    

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙˆØ§Ú©Ø´ÛŒ ØªÙ„ÙØ¸ Ø¢Ú©Ø³ÙÙˆØ±Ø¯: {e}")
        return None, None

# ØªØºÛŒÛŒØ± Ø¯Ø± ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆÙˆÛŒØ³ Ø¢Ú©Ø³ÙÙˆØ±Ø¯ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù† ÙˆÙˆÛŒØ³ Ø¯Ø± Ù„Ø§Ù†Ú¯Ù…Ù†
async def process_word(chat_id, word):
    fetch_oxford_audio_enabled = False
    original_word = word
    parts_data = fetch_longman_data(word)

    # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ„ÙØ¸ Ù†Ø¨ÙˆØ¯ Ùˆ Ù…Ø¹Ø§Ø¯Ù„ Ø¨Ø±ÛŒØªÛŒØ´ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ø§ÙˆÙ†Ùˆ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†
    if not parts_data and word in american_to_british:
        alt_word = american_to_british[word]
        parts_data = fetch_longman_data(alt_word)
        if parts_data:
            word = alt_word  # Ø§Ú¯Ø± Ù†ØªÛŒØ¬Ù‡ Ø¯Ø§Ø´ØªØŒ Ø§ÙˆÙ† Ú©Ù„Ù…Ù‡ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø´Ù‡

    longman_link = build_longman_link(word)
    oxford_link = build_oxford_link(word)

    reply = {
        "chat_id": chat_id,
        "text": f"Ú©Ù„Ù…Ù‡: {original_word}\n\nğŸ“š Longman: {longman_link}\nğŸ“– Oxford: {oxford_link}"
    }
    res = requests.post(API_URL, json=reply)

    preferred = user_preferences.get(chat_id, "american")
    user_pos = "br" if preferred == "british" else "us"
    
    if len(parts_data) == 0: fetch_oxford_audio_enabled = True
    
    for entry in parts_data:
        pos = entry['pos']
        phonetic = entry['phonetic']
        audio_url = entry[preferred]

        caption = f"ğŸ”‰ {word} ({pos}) - {"longman"}"
        if phonetic:
            caption += f"\nğŸ“Œ /{phonetic}/ "
        getAudioUrl(audio_url, preferred, pos, word, chat_id, caption)
    
    if(fetch_oxford_audio_enabled):  
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† ÙˆÙˆÛŒØ³ÛŒ Ø¯Ø± Ù„Ø§Ù†Ú¯Ù…Ù† Ù†Ø¨ÙˆØ¯ØŒ ÙˆÙˆÛŒØ³ Ø¢Ú©Ø³ÙÙˆØ±Ø¯ Ø±Ø§ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†
        oxford_data = fetch_oxford_audio(word,preferred)
        if oxford_data:
            pos = oxford_data.get('pos') if oxford_data.get('pos') else ""
            phonetic = oxford_data.get('phonetic') if oxford_data.get('phonetic') else ""
            audio_url = oxford_data.get('audio_url') if oxford_data.get('audio_url') else ""
            caption = f"ğŸ”‰ {word} ({pos}) - {"oxford"}"
            if phonetic:
                caption += f"\nğŸ“Œ /{phonetic}/"
            getAudioUrl(audio_url, preferred, pos, word, chat_id, caption)      

@app.post("/webhook/{token}")
async def webhook(token: str, request: Request):
    try:
        if token != TOKEN:
            return {"ok": False, "error": "Invalid token"}

        data = await request.json()
        # print("Received data:", data)
        if "message" in data:
            chat_id = data['message']['chat']['id']
            text = data['message'].get('text', '')
            user_id = data['message']['from']['id']

            if text == "/start":
                save_user(user_id)

              
                reply = {
                    "chat_id": chat_id,
                    "text": (
                        "Ø³Ù„Ø§Ù…! ğŸ‘‹ Ø¨Ù‡ Ø±Ø¨Ø§Øª ØªÙ„ÙØ¸ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯.\n\n"
                        "ÛŒÚ© Ú©Ù„Ù…Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ù† Ø§Ø±Ø³Ø§Ù„ Ú©Ù† ØªØ§ Ù„ÛŒÙ†Ú©ØŒ ÙÙˆÙ†ØªÛŒÚ© Ùˆ ØªÙ„ÙØ¸ ØµÙˆØªÛŒ Ø¢Ù† Ø±Ø§ Ø¨Ø±Ø§Øª Ø¨ÙØ±Ø³ØªÙ….\n\n"
                        "âœ… Ù¾ÛŒØ´â€ŒÙØ±Ø¶ ØªÙ„ÙØ¸ ğŸ‡ºğŸ‡¸ American Ø§Ø³Øª.\n"
                        "Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø§ Ø§Ø±Ø³Ø§Ù„ /british ØªÙ„ÙØ¸ Ø±Ø§ Ø¨Ù‡ ğŸ‡¬ğŸ‡§ British ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯ Ùˆ Ø¨Ø§ /american Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒØ¯."
                    )
                }
                res = requests.post(API_URL, json=reply)
                print("ğŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø®ÙˆØ´â€ŒØ¢Ù…Ø¯:")

            elif text == "/british":
                user_preferences[chat_id] = "british"
                reply = {
                    "chat_id": chat_id,
                    "text": "âœ… ØªÙ„ÙØ¸ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±ÙˆÛŒ ğŸ‡¬ğŸ‡§ British ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯!"
                }
                res = requests.post(API_URL, json=reply)
                print("ğŸ“¤ Ø§Ø±Ø³Ø§Ù„ ØªØºÛŒÛŒØ± ØªÙ†Ø¸ÛŒÙ… British:")

            elif text == "/american":
                user_preferences[chat_id] = "american"
                reply = {"chat_id": chat_id, "text": f"Ù¾ÛŒØ§Ù…Øª Ø±Ø³ÛŒØ¯: {text}"}
                res = requests.post(API_URL, json=reply)
                print("ğŸ“¤ Ø¬ÙˆØ§Ø¨ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯:")
                
            elif text == "/stats":
                print("user_id is:", user_id)
                print("ADMINS is:", ADMINS)
                if user_id not in ADMINS:
                    reply = {
                        "chat_id": chat_id,
                        "text": "â›”ï¸ ÙÙ‚Ø· Ø§Ø¯Ù…ÛŒÙ† Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø§Ø² Ø§ÛŒÙ† Ø¯Ø³ØªÙˆØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø¯."
                    }
                else:
                    stats = get_user_stats()
                    reply = {
                        "chat_id": chat_id,
                        "text": (
                            f"ğŸ“Š Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†:\n\n"
                            f"ğŸ‘¥ Ú©Ù„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: {stats['total']}\n"
                            f"ğŸŸ¢ Ø§Ù…Ø±ÙˆØ²: {stats['today']}\n"
                            f"ğŸ•’ Ø¯ÛŒØ±ÙˆØ²: {stats['yesterday']}"
                        )
                    }   
                res = requests.post(API_URL, json=reply)
                print("ğŸ“¤ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯ Ø¢Ù…Ø§Ø±:", res.json)
            else:
                await process_word(chat_id, text)
        return {"ok": True}
    except Exception as e:
        print("âŒ Ø®Ø·Ø§:", e)
        return {"ok": False, "error": str(e)}